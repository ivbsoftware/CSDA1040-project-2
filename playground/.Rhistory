knitr::opts_chunk$set(echo = TRUE)
library("ggplot2")
library("readr")
library("RDSTK")
library("Matrix")
library("dplyr")
library("forcats")
library(tm)
library(stopwords)
library(caTools)
set.seed(777)
# Wrapping long text hook - https://github.com/yihui/knitr-examples/blob/master/077-wrap-output.Rmd
# See usage of print statement with linewidth atrribute in the chunk header.
library(knitr)
hook_output = knit_hooks$get('output')
knit_hooks$set(output = function(x, options) {
# this hook is used only when the linewidth option is not NULL
if (!is.null(n <- options$linewidth)) {
x = knitr:::split_lines(x)
# any lines wider than n should be wrapped
if (any(nchar(x) > n)) x = strwrap(x, width = n)
x = paste(x, collapse = '\n')
}
hook_output(x, options)
})
if(!file.exists("./user-complaints-mining/df.Rds")) {
df <- read_csv(file="../data/Consumer_Complaints.csv.zip",col_names = TRUE)
df <- df[,-c(1,7,9:18)]
df <- df[!is.na(df[,"Consumer complaint narrative"]),] #199,970
df <- df[!is.na(df[,"Company"]),] # no NA's
df <- df[!is.na(df[,"Product"]),] # no NA's
df <- df[!is.na(df[,"Issue"]),] # no NA's
df <- df[!is.na(df[,"Sub-product"]),] # 147,788 total left
df <- df[!is.na(df[,"Sub-issue"]),]   # 81,940 total left
# Converting all but narrative columns to factors
df$Product <- as.factor(df$Product)
df$`Sub-product` <- as.factor(df$`Sub-product`)
df$Issue <- as.factor(df$Issue)
df$`Sub-issue` <- as.factor(df$`Sub-issue`)
df$Company <- as.factor(df$Company)
saveRDS(df, file = "./user-complaints-mining/df.Rds")
gc()
} else {
df <- readRDS("./user-complaints-mining/df.Rds")
}
df
df$Product <- as.factor(df$Product)
df$`Sub-product` <- as.factor(df$`Sub-product`)
df$Issue <- as.factor(df$Issue)
df$`Sub-issue` <- as.factor(df$`Sub-issue`)
df$Company <- as.factor(df$Company)
most_freq_issues_list <- levels(fct_infreq(df$Issue))[1:30]
ggplot() + aes(fct_infreq(df[df$Issue %in% most_freq_issues_list,]$Issue))+
geom_histogram(colour="black", fill="white", stat = "count")+
ylab("Issue Complaints Frequency") + xlab("")+
theme(axis.text.x = element_text(angle =90, hjust = 1))
most_freq_subissues_list <- levels(fct_infreq(df$`Sub-issue`))[1:30]
ggplot() + aes(fct_infreq(df[df$`Sub-issue` %in% most_freq_subissues_list,]$`Sub-issue`))+
geom_histogram(colour="black", fill="white", stat = "count")+
ylab("Sub-Issue Complaints Frequency") + xlab("")+
theme(axis.text.x = element_text(angle =90, hjust = 1))
most_freq_product_list <- levels(fct_infreq(df$Product))[1:30]
ggplot() + aes(fct_infreq(df[df$Product %in% most_freq_product_list,]$Product))+
geom_histogram(colour="black", fill="white", stat = "count")+
ylab("Product Compliants Frequency") + xlab("")+
theme(axis.text.x = element_text(angle =90, hjust = 1))
most_freq_subproduct_list <- levels(fct_infreq(df$`Sub-product`))
ggplot() + aes(fct_infreq(df[df$`Sub-product` %in% most_freq_subproduct_list,]$`Sub-product`))+
geom_histogram(colour="black", fill="white", stat = "count")+
ylab("Sub-Product Complaints Frequency") + xlab("")+
theme(axis.text.x = element_text(angle =90, hjust = 1))
most_freq_company_list <- levels(fct_infreq(df$Company))[1:30]
ggplot() + aes(fct_infreq(df[df$Company %in% most_freq_company_list,]$Company))+
geom_histogram(colour="black", fill="white", stat = "count")+
ylab("Company Complaints Frequency") + xlab("")+
theme(axis.text.x = element_text(angle =90, hjust = 1))
set.seed(123)
sample = sample.split(df$`Consumer complaint narrative`, SplitRatio = .5)
train = subset(df, sample == TRUE)
test  = subset(df, sample == FALSE)
if(!file.exists("./user-complaints-mining/myCorpus.Rds")) {
myCorpus <- Corpus(VectorSource(train$`Consumer complaint narrative`))
myCorpus <- tm_map(myCorpus, removePunctuation)
myCorpus <- tm_map(myCorpus, removeNumbers)
myCorpus <- tm_map(myCorpus, tolower)
myStopwords <- c(stopwords(language="en", source="smart"),
"xx", "xxxx", "xxxxxxxxxxxx", "xxxxxxxx",
"told", "well", "month", "year"
)
myCorpus <- tm_map(myCorpus, removeWords, myStopwords)
myCorpus <- tm_map(myCorpus, stripWhitespace)
saveRDS(myCorpus, file = "./user-complaints-mining/myCorpus.Rds")
gc()
} else {
myCorpus <- readRDS("./user-complaints-mining/myCorpus.Rds")
}
print(myCorpus[1:5]$content)
dictCorpus <- myCorpus
myCorpus <- tm_map(myCorpus, stemDocument)
print(myCorpus[1:5]$content)
### Stem completion - failed on out of memory, skipping for now
myCorpus <- tm_map(myCorpus, stemCompletion, dictionary=dictCorpus)
library(wordcloud)
m <- as.matrix(myDtm)
if(!file.exists("./user-complaints-mining/myDtm.Rds")) {
myDtm <- TermDocumentMatrix(myCorpus, control = list(minWordLength = 1))
rowTotals <- apply(myDtm , 1, sum) #Find the sum of words in each Document
myDtm <- myDtm[rowTotals > 0, ] #remove all docs without words
saveRDS(myDtm, file = "./user-complaints-mining/myDtm.Rds")
gc()
} else {
myDtm <- readRDS("./user-complaints-mining/myDtm.Rds")
}
inspect(myDtm)
library(wordcloud)
m <- as.matrix(myDtm)
myDtm <- TermDocumentMatrix(myCorpus,  control = list(weighting = weightTfIdf))
rowTotals <- apply(myDtm , 1, sum) #Find the sum of words in each Document
saveRDS(myDtm, file = "./user-complaints-mining/myDtmIDF.Rds")
View(myDtm)
View(myDtm)
View(myDtm)
View(myDtm)
myDtm <- TermDocumentMatrix(myCorpus,  control = list(weighting = weightTfIdf))
inspect(myDtm)
freq.terms <- findFreqTerms(myDtm, lowfreq=1)
freq.terms
freq.terms <- findFreqTerms(myDtm, lowfreq=5)
freq.terms
myDtm
freq=rowSums(as.matrix(myDtm))
head(freq,10)
